{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install librosa\n",
    "# %pip install soundfile\n",
    "# %pip install tensorflow\n",
    "# %pip install scikit-learn\n",
    "# %pip install keras\n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from IPython.display import display, Audio\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./combined_files\"\n",
    "\n",
    "shutil.rmtree(output_dir, ignore_errors=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Contents of {output_dir} cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./Dataset\"\n",
    "output_dir = \"./combined_files\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "speaker_folders = os.listdir(dataset_path)\n",
    "non_speaker = ['_background_noise_', 'other']\n",
    "\n",
    "for nspkr in non_speaker:\n",
    "    if nspkr in speaker_folders:\n",
    "        speaker_folders.remove(nspkr)\n",
    "\n",
    "num_files_to_combine = 360\n",
    "\n",
    "for speaker_folder in speaker_folders:\n",
    "    speaker_folder_path = os.path.join(dataset_path, speaker_folder)\n",
    "\n",
    "    wav_files = [f\"{i}.wav\" for i in range(num_files_to_combine)]\n",
    "\n",
    "    combined_audio = []\n",
    "    for wav_file in wav_files:\n",
    "        wav_file_path = os.path.join(speaker_folder_path, wav_file)\n",
    "        audio, sr = librosa.load(wav_file_path, sr=None)\n",
    "        combined_audio.extend(audio)\n",
    "\n",
    "    output_file_path = os.path.join(output_dir, f\"{speaker_folder}_combined.wav\")\n",
    "    sf.write(output_file_path, combined_audio, sr)\n",
    "\n",
    "print(\"Combination complete. Combined files saved in:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(audio_path):\n",
    "    display(Audio(filename=audio_path))\n",
    "\n",
    "for speaker_folder in os.listdir(output_dir):\n",
    "    audio_path = os.path.join(output_dir, speaker_folder)\n",
    "    print(f\"Click the play button to listen: {audio_path}\")\n",
    "    play_audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio_features(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    speaker_name = os.path.basename(audio_path).split('_')[0]\n",
    "\n",
    "    # Plot the waveform\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title(f'Waveform - {speaker_name}')\n",
    "\n",
    "    # Plot the spectrogram\n",
    "    plt.subplot(3, 1, 2)\n",
    "    D = librosa.amplitude_to_db(abs(librosa.stft(y)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Spectrogram - {speaker_name}')\n",
    "\n",
    "    # Plot the MFCCs\n",
    "    plt.subplot(3, 1, 3)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'MFCCs - {speaker_name}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for audio_path in os.listdir(output_dir):\n",
    "    if audio_path.endswith('Arul_combined.wav'):\n",
    "        plot_audio_features(os.path.join(output_dir, audio_path))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(parent_dir, speaker_folders):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i, speaker_folder in enumerate(speaker_folders):\n",
    "        speaker_folder_path = os.path.join(parent_dir, speaker_folder)\n",
    "\n",
    "        for filename in os.listdir(speaker_folder_path):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                file_path = os.path.join(speaker_folder_path, filename)\n",
    "                audio, sr = librosa.load(file_path, sr=None, duration=1)\n",
    "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "                \n",
    "                # Normalize MFCC features\n",
    "                mfccs = StandardScaler().fit_transform(mfccs)\n",
    "                \n",
    "                features.append(mfccs.T)\n",
    "                labels.append(i)\n",
    "\n",
    "        print(\"Finished feature extraction from\", len(features), \"files\", features[-1].shape)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "X, y = extract_features(dataset_path, speaker_folders)\n",
    "for feature in X[:1]:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "label_encoder.classes_ = np.array(speaker_folders)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Validation Data Shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(speaker_folders), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Check if EarlyStopping triggered\n",
    "if early_stopping.stopped_epoch > 0:\n",
    "    print(\"Early stopping triggered at epoch\", early_stopping.stopped_epoch + 1)\n",
    "else:\n",
    "    print(\"Training completed without early stopping\")\n",
    "\n",
    "# Plot training vs validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_probabilities = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Decode labels back to original format\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_decoded, y_pred_decoded, labels=speaker_folders)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_decoded, y_pred_decoded)\n",
    "print(f\"Test Evaluation Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test_decoded, y_pred_decoded, labels=speaker_folders, average='weighted')\n",
    "print(f\"Weighted F1 Score: {f1}\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=speaker_folders, yticklabels=speaker_folders)\n",
    "\n",
    "# Rotate x-axis labels by 45 degrees\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
