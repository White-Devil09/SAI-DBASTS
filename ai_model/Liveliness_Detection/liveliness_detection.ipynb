{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install resampy\n",
    "# %pip install tqdm\n",
    "# %pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"../Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(audio_file_path, Tag):\n",
    "    ad, sr = librosa.load(audio_file_path)\n",
    "\n",
    "    spec = np.abs(librosa.stft(ad))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "\n",
    "    mel_spect = librosa.feature.melspectrogram(y=ad, sr=sr)\n",
    "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "\n",
    "    chroma = librosa.feature.chroma_cqt(y=ad, sr=sr, bins_per_octave=36)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=ad, sr=sr)\n",
    "\n",
    "    fig, ax = plt.subplots(5, 1, figsize=(10, 15), constrained_layout=True)\n",
    "    fig.suptitle(f'Visualization of {Tag} audio', fontsize=16)\n",
    "\n",
    "    ax[0].plot(ad)\n",
    "    ax[0].set_title(f'{Tag} audio Waveform')\n",
    "\n",
    "    img = librosa.display.specshow(spec, sr=sr, x_axis='time', y_axis='log', ax=ax[1])\n",
    "    fig.colorbar(img, ax=ax[1], format=\"%+2.0f dB\")\n",
    "    ax[1].set_title(f'{Tag} audio spectrogram')\n",
    "\n",
    "    img = librosa.display.specshow(mel_spect, sr=sr, x_axis='time', y_axis='mel', ax=ax[2])\n",
    "    fig.colorbar(img, ax=ax[2], format=\"%+2.0f dB\")\n",
    "    ax[2].set_title(f'{Tag} audio Mel Spectrogram')\n",
    "\n",
    "    img = librosa.display.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma', ax=ax[3])\n",
    "    fig.colorbar(img, ax=ax[3], format=\"%+2.0f dB\")\n",
    "    ax[3].set_title(f'{Tag} audio Chroma')\n",
    "\n",
    "    img = librosa.display.specshow(mfcc, sr=sr, x_axis='time', ax=ax[4])\n",
    "    fig.colorbar(img, ax=ax[4], format=\"%+2.0f dB\")\n",
    "    ax[4].set_title(f'{Tag} audio MFCC')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Dataset/DEMO'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m demo_audio_paths \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(audio_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEMO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_audio_paths\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      5\u001b[0m         real_audio_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(demo_audio_paths, item)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Dataset/DEMO'"
     ]
    }
   ],
   "source": [
    "demo_audio_paths = os.path.join(audio_file_path, 'DEMO')\n",
    "\n",
    "for item in os.listdir(demo_audio_paths):\n",
    "    if item.find(\"original\") != -1:\n",
    "        real_audio_path = os.path.join(demo_audio_paths, item)\n",
    "    else:\n",
    "        fake_audio_path = os.path.join(demo_audio_paths, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(real_audio_path, \"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(fake_audio_path, \"Fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/56 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n\n----> resampy = lazy.load(\"resampy\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(files):\n\u001b[0;32m      9\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(audio_file_path, folder, file)\n\u001b[1;32m---> 10\u001b[0m     audio, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkaiser_fast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     mfcc_features \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m     12\u001b[0m     mfcc_features_scaled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(mfcc_features\u001b[38;5;241m.\u001b[39mT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:193\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    190\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     sr \u001b[38;5;241m=\u001b[39m sr_native\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:678\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[0;32m    670\u001b[0m         soxr\u001b[38;5;241m.\u001b[39mresample,\n\u001b[0;32m    671\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    675\u001b[0m         quality\u001b[38;5;241m=\u001b[39mres_type,\n\u001b[0;32m    676\u001b[0m     )\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 678\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mresampy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m(y, orig_sr, target_sr, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mres_type, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[0;32m    681\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mfix_length(y_hat, size\u001b[38;5;241m=\u001b[39mn_samples, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lazy_loader\\__init__.py:117\u001b[0m, in \u001b[0;36mDelayedImportErrorModule.__getattr__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__frame_data\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis error is lazily reported, having originally occured in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  File \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(fd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_context\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    122\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n\n----> resampy = lazy.load(\"resampy\")"
     ]
    }
   ],
   "source": [
    "data, labels = [], []\n",
    "\n",
    "folders = ['FAKE', 'REAL']\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(audio_file_path, folder))\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        file_path = os.path.join(audio_file_path, folder, file)\n",
    "        audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfcc_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "        mfcc_features_scaled = np.mean(mfcc_features.T, axis=0)\n",
    "\n",
    "        data.append(mfcc_features_scaled)\n",
    "        labels.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame({'features': data, 'labels': labels})\n",
    "print(feature_df.head())\n",
    "print(feature_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(labels):\n",
    "    le = LabelEncoder().fit(labels)\n",
    "    print(labels.name, le.classes_)\n",
    "    return le.transform(labels)\n",
    "\n",
    "feature_df['labels'] = label_encoder(feature_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feature_df.features.tolist())\n",
    "y = np.array(feature_df.labels.tolist())\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "y_resampled = to_categorical(y_resampled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "num_labels = len(feature_df['labels'].unique())\n",
    "input_shape = feature_df['features'][0].shape\n",
    "\n",
    "print(f\"Input shape : {input_shape}\")\n",
    "print(f\"Number of labels : {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_shape=input_shape),\n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(256),\n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(128),\n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_labels),\n",
    "    Activation(\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=2, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss : {test_loss}\")\n",
    "print(f\"Test accuracy : {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio_file_path, model):\n",
    "    audio, sr = librosa.load(audio_file_path, res_type='kaiser_fast')\n",
    "    mfcc_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    mfcc_features_scaled = np.mean(mfcc_features.T, axis=0)\n",
    "    mfcc_features_scaled = np.expand_dims(mfcc_features_scaled, axis=0)\n",
    "    prediction = model.predict(mfcc_features_scaled)\n",
    "\n",
    "    print(f\"Prediction : {folders[np.argmax(prediction[0])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = '../Speaker_Identification/combined_files/Benjamin_Netanyau_combined.wav'\n",
    "predict(real_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currTime = pd.Timestamp.now().strftime(\"%Y%m%d%H%M\")\n",
    "# model.save(f'weights/model-{currTime}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
